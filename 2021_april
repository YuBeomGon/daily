4/1
to do 
1. open data로 ssd detection training, validation(tensorflow)
   tfrecord를 생성 후 학습할때 augmentation어떻게 들어가는지, tensorflow object api 확인
   object detection api를 안 쓸수는 없는지 확인
2. open data classify using tensorflow
3. tensorflow 기초 다지기
4. detr data bbox 확인

done
1. screen 명령어 확인
   https://ddiri01.tistory.com/319
   screen -S, -ls, -R, ctrl+a 후에 명령어 입력, 
   ctrl+a, d  (detach) 
   screen -S [sessionID] -X quit 또는 attatch 후 ctrl+d 또는 exit
   세션(screen)내에 terminal 추가

ctrl+a, c
세션 아래부분에 0 bash  [1 bash] 이렇게 표시된다.
2개의 bash창 중에 뒤의것이 선택되었다는것 
창이동하기 : ctrl+a, 0 : 0번째 창으로이동 
ctrl+a,1 : 1번째 창으로 이동. 
창종료하기 : terminal 종료하듯이 exit해주면됨
   
4/2
to do 
1. object detection 논문 deep reivew (fast review, ssd)
2. domain data 관련 이해, area 등 추가 확인
3. 

done
1. 갈아먹는 
   https://yeomko.tistory.com/13

further
1. object detection 논문 전체 리뷰
2. image augmentation 관련
3. pathology, cytology, papsmear 논문 및 augmentation관련 리뷰

4/6
done 
Object detection review
https://yeomko.tistory.com/category/%EA%B0%88%EC%95%84%EB%A8%B9%EB%8A%94%20Object%20Detection
Deepsystems review
https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.p

4/7
기존 crop시 bbox 잘못 잡는 에러 햬결
세로로 세워져 있는 image에 한해 transpose및 flip을 시켜준다.
why flip?? 어떤 history가 있을까?
혹시 세로로 세워져 있는 image중 flip이 안되어 있는 것도 있지 않을까??

4/8
1. 준환님 based classification code를 detection code로 customizing 관련
   tf.hub example code 확인
1. tensorflow 1.14
   2. 1 class(abnormal) object detection training 시작
   3. 2 class의 경우 IOU 0.5 기준 precision 약 0.6 정도
      아마도 전체 slide에 대한 sensitivity와 specificity를 말한 듯
4. tensorflow 2.4
   동일하게 2 class에 대해 detection해서 loss약 2 정도 나왔으나 evaluation시 끝 부분에서 error 발생함.
     File "/home/beomgon/anaconda3/envs/tfssd/lib/python3.8/site-packages/numpy/core/function_base.py", line 113, in linspace
       num = operator.index(num)
   TypeError: 'numpy.float64' object cannot be interpreted as an integer
   
4/9
1. tensorflow hub object detection관련 확인, 어려울 듯
   keras.Layer도 마찬가지
   kaggle에 yolov3 버전으로 하자.
   
2. papsmear image는 default가 가로가 맞다.
   실제 bbox label과 width, height가 그렇게 되어 있다. 
   일부 이미지가 세로로 세워져 있다면 체크해서 flip 및 transpose를 해 줘야 한다.
   
4/14
object detection bbox
https://leimao.github.io/blog/Bounding-Box-Encoding-Decoding/

albumentation bug report, min_visibility=1.0일때 bo bounding box return 
약 30000번 돌려서 evaluation한 결과입니다.
batch size를 32로 1/4로 줄여서 80000번은 돌려야
예전과 비슷할 것 같습니다.
one class(abnormal) detection입니다.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.817
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.491
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000


4/15
to do
1. ssd paper reivew
2. ssd에서 center x, y, width, height가 bbox parameter로 들어간다 (by 논문, 실제 코드 구현 확인해 보자.)
3. bbox regression 이해
4. swin transformer
5. mobile net

done
1. mobile net
   vgg 기반 backbon에서 depth wise convolution + point conv를 도입해서 연산량을 감소시킨 모델
2. swin transformer 리뷰
   cnn 과 유사한 architecture를 갖도록 design
3. 약 10,0000 step training, 결과가 더 좋아짐을 확인함.
   pb file export 후, tf lite 변환 후, inferece 실행했으나 모든 결과가 0으로 나옴
   web에서 tf.saved_file.load('path')에서 ~ 인식 에러
   모델 로드 시 signiture까지 넣어줘야 model call이 됨.

4. tensorflow object detection api training for custom dataset
https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#evaluating-the-model-optional

5. tensorflow bounding box format 관련
   model에 따라 dataset에 따라 box의 format이 다르다. ex(xmin, ymin, xmax, ymax or centerx, centery, widht, height ...)
   tensorflow object detection api에서는
   xmin, ymin, xmax, ymax를 각각 x/widht, y/height로 normalize해서 통일화된 format으로 보내주고,   
   내부적으로 model에 따라 변경해주는 부분이 각 모델 코드에 있을 것 같다.

4/20
done 
1. retinanet paper review
2. softmax and log likehood loss gradient backpropagation 스터디
3. tensorflow object detection api code review
   model, loss, export for inference, mobile inference check
   mobile inference시 내부적으로 preprocess함수가 불린다.
   그냥 inference시 default로 input tensor가 unit로 되어 있다.

do
1. tensorflow object detection api code study
   loss, input data loader, model
2. export graph, inference시 코드 flow
   mobile serving 확인
3. efficient det paper reivew
4. pytorch retinanet code review
   anchor box, FPN, loss, 등 코드 확인해 보자.
5. model export, tflite시 code flow check, preporcess를 하는지 안하는지 확인 필요.

