4/1
to do 
1. open data로 ssd detection training, validation(tensorflow)
   tfrecord를 생성 후 학습할때 augmentation어떻게 들어가는지, tensorflow object api 확인
   object detection api를 안 쓸수는 없는지 확인
2. open data classify using tensorflow
3. tensorflow 기초 다지기
4. detr data bbox 확인

done
1. screen 명령어 확인
   https://ddiri01.tistory.com/319
   screen -S, -ls, -R, ctrl+a 후에 명령어 입력, 
   ctrl+a, d  (detach) 
   screen -S [sessionID] -X quit 또는 attatch 후 ctrl+d 또는 exit
   세션(screen)내에 terminal 추가

ctrl+a, c
세션 아래부분에 0 bash  [1 bash] 이렇게 표시된다.
2개의 bash창 중에 뒤의것이 선택되었다는것 
창이동하기 : ctrl+a, 0 : 0번째 창으로이동 
ctrl+a,1 : 1번째 창으로 이동. 
창종료하기 : terminal 종료하듯이 exit해주면됨
   
4/2
to do 
1. object detection 논문 deep reivew (fast review, ssd)
2. domain data 관련 이해, area 등 추가 확인
3. 

done
1. 갈아먹는 
   https://yeomko.tistory.com/13

further
1. object detection 논문 전체 리뷰
2. image augmentation 관련
3. pathology, cytology, papsmear 논문 및 augmentation관련 리뷰

4/6
done 
Object detection review
https://yeomko.tistory.com/category/%EA%B0%88%EC%95%84%EB%A8%B9%EB%8A%94%20Object%20Detection
Deepsystems review
https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&loop=false&delayms=3000&slide=id.p

4/7
기존 crop시 bbox 잘못 잡는 에러 햬결
세로로 세워져 있는 image에 한해 transpose및 flip을 시켜준다.
why flip?? 어떤 history가 있을까?
혹시 세로로 세워져 있는 image중 flip이 안되어 있는 것도 있지 않을까??

4/8
1. 준환님 based classification code를 detection code로 customizing 관련
   tf.hub example code 확인
1. tensorflow 1.14
   2. 1 class(abnormal) object detection training 시작
   3. 2 class의 경우 IOU 0.5 기준 precision 약 0.6 정도
      아마도 전체 slide에 대한 sensitivity와 specificity를 말한 듯
4. tensorflow 2.4
   동일하게 2 class에 대해 detection해서 loss약 2 정도 나왔으나 evaluation시 끝 부분에서 error 발생함.
     File "/home/beomgon/anaconda3/envs/tfssd/lib/python3.8/site-packages/numpy/core/function_base.py", line 113, in linspace
       num = operator.index(num)
   TypeError: 'numpy.float64' object cannot be interpreted as an integer
   
4/9
1. tensorflow hub object detection관련 확인, 어려울 듯
   keras.Layer도 마찬가지
   kaggle에 yolov3 버전으로 하자.
   
2. papsmear image는 default가 가로가 맞다.
   실제 bbox label과 width, height가 그렇게 되어 있다. 
   일부 이미지가 세로로 세워져 있다면 체크해서 flip 및 transpose를 해 줘야 한다.
   
4/14
object detection bbox
https://leimao.github.io/blog/Bounding-Box-Encoding-Decoding/

albumentation bug report, min_visibility=1.0일때 bo bounding box return 
약 30000번 돌려서 evaluation한 결과입니다.
batch size를 32로 1/4로 줄여서 80000번은 돌려야
예전과 비슷할 것 같습니다.
one class(abnormal) detection입니다.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.817
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.615
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.163
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.491
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.641
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000


4/15
to do
1. ssd paper reivew
2. ssd에서 center x, y, width, height가 bbox parameter로 들어간다 (by 논문, 실제 코드 구현 확인해 보자.)
3. bbox regression 이해
4. swin transformer
5. mobile net

done
1. mobile net
   vgg 기반 backbon에서 depth wise convolution + point conv를 도입해서 연산량을 감소시킨 모델
2. swin transformer 리뷰
   cnn 과 유사한 architecture를 갖도록 design
3. 약 10,0000 step training, 결과가 더 좋아짐을 확인함.
   pb file export 후, tf lite 변환 후, inferece 실행했으나 모든 결과가 0으로 나옴
   web에서 tf.saved_file.load('path')에서 ~ 인식 에러
   모델 로드 시 signiture까지 넣어줘야 model call이 됨.

4. tensorflow object detection api training for custom dataset
https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#evaluating-the-model-optional

5. tensorflow bounding box format 관련
   model에 따라 dataset에 따라 box의 format이 다르다. ex(xmin, ymin, xmax, ymax or centerx, centery, widht, height ...)
   tensorflow object detection api에서는
   xmin, ymin, xmax, ymax를 각각 x/widht, y/height로 normalize해서 통일화된 format으로 보내주고,   
   내부적으로 model에 따라 변경해주는 부분이 각 모델 코드에 있을 것 같다.

4/20
done 
1. retinanet paper review
2. softmax and log likehood loss gradient backpropagation 스터디
3. tensorflow object detection api code review
   model, loss, export for inference, mobile inference check
   mobile inference시 내부적으로 preprocess함수가 불린다.
   그냥 inference시 default로 input tensor가 unit로 되어 있다.
4. test results
   batch size 12, about 10,000 step, mobile ssd 640x640
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.828
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.570
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.287
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.513
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.536
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.508
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.502
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.663
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644
 
5. mobile과 pc에서 tflite model을 이용한 inference 결과가 서로 다름
   Albumentation resize option, inter_linear로 app의 bi lenear와 동일함.
   

do
1. tensorflow object detection api code study
   loss, input data loader, model
2. export graph, inference시 코드 flow
   mobile serving 확인
3. efficient det paper reivew
4. pytorch retinanet code review
   anchor box, FPN, loss, 등 코드 확인해 보자.
5. model export, tflite시 code flow check, preporcess를 하는지 안하는지 확인 필요.

4/21
do
1. efficient net paper reivew, fine tuning using tensorflow object detection api
2. 다양한 aspect ratio와 scale을 줘서 fine tuning해보자. loss ft에서 regression의 loss를 줄일 것..
3. pytorch retinanet code review
   code에서 bbox와 classification loss, iou 관계 등 확인할 것..

done
1. ssd mobilenet + fpn 640x640, 100,000 step test result. (batch size, 12
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.516
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.838
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.595
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.313
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.514
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.507
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.661
 
 2. ssd mobilenet + fpn 320x320, 30,000 step test result. (batch size, 32, full anchor box, 3~7 level)
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.809
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.451
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.606
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.160
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.477
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.631
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.695
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 
 3. ssd mobilenet + fpn 320x320, 50,000 step test result. (batch size, 32, full anchor box, 3~7 level)
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.841
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.547
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.481
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.619
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.491
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.633
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 
 4.  ssd mobilenet + fpn 320x320, 100,000 step test result. (batch size, 32, full anchor box, 3~7 level, class vs local loss weight : 1 vs 0.2)
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.502
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.852
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.549
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.166
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.491
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.699
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 
loss 비율 조정은 성능에 크게 영향이 없어 보인다.

4. train1.sh training, 3번 이어서 10,0000 step test
   train.sh training1 0.2 : 1의 비율로 다르게 줘서 학습시킴.
   
4. papsmear 이전 버전, PC와 mobile이 서로 달랐다고 함..


0421
1. detection model 바꿔서 테스트 해 보자.
2. 전체 test set에 대해 돌려서 confusion matrix 만들어 볼 것.
3. threshold 비교하며, 적절한 threshold 찾기
4. NMS 구현.
5. pytorch retinanet, training 및 code 공부, anchor box, IOU, loss, NMS 등 확인해 보자.

0423

test resutl (ssd fpn mobilenet 320, 130000 step)
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.859
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.567
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.496
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.642
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.168
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.500
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.717
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000

0423
efficientdet640 20000, batch_size 6
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.768
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.478
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.204
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.440
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.477
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.482
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.542
 
 0426
 1. NMS algorithm 확인 및 구현 테스트
 2. retinanet code review
 3. threshold 바꿔가면서 전체 test set에 대해 test?
    or 각 pass fail별로 특징 확인
    
 1. NMS 
 https://github.com/BichenWuUCB/squeezeDet/blob/master/src/utils/util.py
 https://dyndy.tistory.com/275
 
 2. threshold에 따른 recall, precision (3500중 500개로 테스트)
    0.2 : p 0.81, 0.64, f1 0.71 num_pred 1649
    
    0.25 : p 0.84, 0.62, f1 0.71 num_pred 1562
    
    0.3 :  p 0.86, r 0.60, f1 0.71 num_pred 1465
    
    0.4 : p 0.90 r 0.55 f1 0.68
    
    0.5 : p 0.97 r 0.48, f1 0.64, num_pred 1042

0.25
duration  763.7069249153137
7950 14054 10740
precision : 0.7402234636871509
recall : 0.5656752525971254
f1 score 0.6412841816568525

0.2
duration  763.1596565246582
8214 14054 11429
precision : 0.7186980488231691
recall : 0.5844599402305394
f1 score 0.6446650708315348
228
3431
0.06645292917516758

0.15 + 최소 한개 포함

SCL, 5월달 data 받을 예정, 4개월 내에 AI model 개발(9월 안), 95%, 5분 , wsi image
성모병원 컨소시엄, 4월 말 미팅, 2년 계획
tensorflow object detection api 를 이용 tuning, + search위주로, code 리뷰 (pytorch 위주로)

4/28
object detection without anchorbox paper review
centernet, cornernet, FCOS etc
retinanet pytorch code reveiw
kaggle retinanet training

done
1. cpc 관련 논문 리뷰( contrastive predictive coding, self supervised learning으로 uspervised learning을 뛰어 넘었다고)
2. gradient cliping vs l2 regularization
   g : 상대적인 비율을 이용, batch norm을 사용 안할시, gradient가 크게 나오는 것을 clipping으로 해결 가능
   l2 : gradient의 절대적인 값을 이용
   
   
4/29
1. centernet training in server
2. pytorch retinanet training with coco

efficientdetd1 640, batch_size 6, step size 353000, about 2.5 day fine tuning, loss 0.182
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.518
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.840
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.590
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.302
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.526
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.516
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.497
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.662
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.729
 inference in pc is slow than ssd320, about 3 times more time is needed

 98% detection accuracy, threshold = 0.15


