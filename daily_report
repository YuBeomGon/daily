2020/01/31
DeepSpeech training 도중 아래와 같은 cudnn error 발생
Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above
인터넷을 찾아본 결과 cuda/cudnn과 텐서플로우 등의 호환성 문제로 보이며 아직 cudnn이나 텐서플로우 등이 완벽하게 호환되지 않는 듯 하다. 
되다가 안된다는 경우가 꽤 있음.
ternsorflow gpu version을 1.15에서 1.14로 downgrade후에 잘 동작한다. 1.15는 계속 안된다.
이유를 알수는 없지만 호환성이 깨진듯

위 이슈 관련 시도해 보았던 것
1. 코드 리뷰 - 의외로 사소한 실수일 수 있다.
2. nvidia gpu driver 재설치(clean 후 reinstall)
3. cuda, cudnn 재설치
4. tensorflow를 비롯한 python 가상환경 재설치
5. 전역 pip list 삭제..
6. tensorflow downgrade to 1.14 후 비로소 training 정상 동작.


2020/02/03
1/31 cudnn issue관련 training은 잘 되었지만 inference시에 ctc_decoder를 불러오는 부분에서 segmentation error 발생, 
ctc decoder는 c++로 개발된 모듈을 binary형태로 파이썬에서 불러오는 형태로 현재 디버깅을 하기가 쉽지 않아 포맷 진행
format 후에 pip3 -r requirement.txt 중 아래와 같은 error 발생, 
building '_webrtcvad' extension
  creating build/temp.linux-x86_64-3.6
  creating build/temp.linux-x86_64-3.6/cbits
  creating build/temp.linux-x86_64-3.6/cbits/webrtc
  creating build/temp.linux-x86_64-3.6/cbits/webrtc/common_audio
  creating build/temp.linux-x86_64-3.6/cbits/webrtc/common_audio/signal_processing
  creating build/temp.linux-x86_64-3.6/cbits/webrtc/common_audio/vad
  x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWEBRTC_POSIX -Icbits -I/usr/include/python3.6m -I/home/beomgon2/deepspeech-train-venv/include/python3.6m -c cbits/pywebrtcvad.c -o build/temp.linux-x86_64-3.6/cbits/pywebrtcvad.o
  cbits/pywebrtcvad.c:1:10: fatal error: Python.h: No such file or directory
   #include <Python.h>
            ^~~~~~~~~~
  compilation terminated.
  error: command 'x86_64-linux-gnu-gcc' failed with exit status 1
git lfs 설치 중 apt package관련 설정등이 바뀐 것으로 보이며 apt-update 이후에 정상설치

텐서플로우 관련 한글번역 문서 study 중


0205
1. 딥러닝 교육 관련 소제목 및 내용 간략히 정리
2. 2/3일에서 zeroth data기준 csv file format으로 변환, but 이후 training시 아래 에러 재발생
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
     [[{{node tower_0/conv1d/Conv2D}}]]
     v0.7.0-alpha.1 버전에서 tensorflow-gpu version 1.14로 해도 여전히 발생, 
     git latest code base로 변환, git 설치 문서 확인 중 TF_FORCE_GPU_ALLOW_GROWTH environment variable to true 로 세팅하라는 부분 확인
     세팅 후 여전히 같은 에러 발생
     tensorflow-gpu version 1.15에서 1.14로 다운그레이드 후 training 성공
     
     Latest branch가 아닌 release branch로 받아서 테스트해야 두 PC의 환경이 완전히 똑같다. 
     
3. kenlm에서 MAX order가 6이고 7 이상으로 설정시 cmake를 이용해 빌드를 다시 해야 한다. 
     cmake -DKENLM_MAX_ORDER=10 ..
    파이썬 연동치 ds_decoder init할때 ngram order가 6을 초과해서 error 발생,
    6으로 바꾼 후 inferencing 성공
    자모에서 더 세분화할 경우를 테스트하려면 max_order를 10 이상으로 설정할 수 있어야 한다. 
    
4. tensorflow 공식문서 한글 번역본 공부 
   https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/how_tos/using_gpu/
   v1.0에 대한 문서로 옛날 것, latest 한글 번역본 같이 볼 필요 있다. 
   특정 변수만 저장하고 loading할수 있다. 즉 pretrained model의 변수를 layer 1~5까지 집어넣고 6번째 layer를 affine layer로 넣는 식으로 해서 transfer learning
   등 가능
   freezing  multi gpu 사용 등 cifar 예제 확인해 보자.
   파이썬 사용자 친화적으로 편하지만 연산 속도가 느리다. 수치 연산이나 빅데이터 분석 등 연산량이 많은 작업을 위해 파이썬을 쓰는 것이 아닌, C++ 등으로 작성한 후
   컴파일해서 해당 binary를 파이썬에서 import해서 쓰면 속도가 빠를 것이다. numpy나 scikitlearn 등이 이와 같은 목적으로 만들어진 것.
   numpy를 사용할 수도 있지만 C++과 python과의 IO부분에서 병목현상이 발생할 수 있으므로 전체 deep learning의 연산부분은 하나의 static graph로 표현하고
   session을 열어서 계산을 한번에 하는 것이 tensorflow이다. PYthon IO는 처음과 끝에 한번씩만 존재.
   tensorflow에서 사용자 정의 operation등을 제공, tensorflow code를 다운받은 후 bazel을 이용한 빌드 필요.
   
   Bazel이란 - npm 및 pip와 유사한 package manager로서 c++에서 사용 가능하며 tensorflow package를 빌드할 때 사용된다. 
   sudo apt-get install python3 python3-dev python3-pip 각각의 차이, 앞의 둘은 파이썬 설치 rel/dev branch등의 차이인 듯, pip는 pip python package manager
   
   tensorflow source build 중 ./configure에서 error 발생
   
   
   0206
1. DeepSpeech code review, data Feeding and modeling, input[batch_size, seq_len, feature] * weight[feature * num_hidden] 을 하면 자동적으로 
   seq_len을 따라 dense layer가 수행이된다. fully connected layer를 통해서 feature를 뽑아낸다. 
2. AI hub data training, 2 PC에서 one epoch당 약 90분 정도 소요됨
3. tensorflow 한글 번역본 문서 확인
4. 음성 발성 및 한글 창제 관련 서치
5. paddle/DeepSpeech2, 바이두의 endtoend model로서 자체 Deeplearning framework(paddle)을 사용한다. 
   Openseq2seq, lingvo, 조금 더 분석 필요, 코드가 잘 눈에 들어오지 않음.
todo(장기적으로)
1. Tensorflow 간단한 예제부터 C++ code 참조해보자. DeepSpeech외 다른 ASR EndtoEnd model 확인해 볼것.
2. 텐서팩을 이용해서 아예 새로 구현하는 것?? 텐서팩 간단히 확인할 것
3. 텐서플로우 v1, v2, 2.0 등 정리 필요
   
     
w
