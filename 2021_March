3/8~3/15
1. object detection관련 기존 과제 backup
(Papsmier, HPV, 동결절편)
2. Linux setting

3/15
to do 
1. Object detection 관련 논문 fast review
   ssd, faster rcnn, mask rcnn, 
2. DETR fast review
3. papsmier 및 DETR 관련 코드 리뷰 및 mixup
4. data 관련 확인, 
   train/test split시 사람별로 나눌 필요 존재?
   모든 object에 bounding box 할 필요 존재?
   data 확인해 보자.
  

done 
1. SSD - hard negative mining - for solving class imbalancing,
         check background bounding box with small loss, (3 vs 1, background vs non background)
         sorting후 loss가 작은 것 3배 sampling해서 학습시 사용한다. 
         
       - small object 잘 못찾는다, 처음 feature를 뽑는 layer에서 아직 abstraction이 충분히 잘 이뤄지지 않음 -> retina net
       - SSD에서는 augmentation으로 극복을 한다.
       - VGG16대신 가벼운 network를 사용시 시간을 더 줄일 수 있다.
       
2. DETR
   set problem, No heuristic like anchor box, NMS.
   Backbone resnet 50, 101, positional embeding 
   Transformer, two FFN for class and bbox
   two loss for matching and backpropagation
   for class imbalance, background class, loss*1/10
   
   Deformabel DETR
   DETR is too long to train 200 epoch, multiple feature impossible(seq len should not be long)
   deformable attention is introduced, -> multiple feature is ok
   
   Locating Object without Bounding Boxes
   not bounding box but point in case of small object
   hausdorf loss
   what is a deformable convolution??
   
   Train/Test set split - random split, No Personal information, but still need to check how to make test data
   regarding Normal class bounding box
      - Bg, high, low(normal in bg)
      - annotate all normal case? -> too much normal case, hard to annotate?
      - annotate several normal case, using loss ft(undersample bg case, by sorting)
      
   code review - bbox and image print 
   
3/16
to do
1. deformable convolution/attention review
   자연어처리 pretraining - vision fine tuning
2. data 관련 확인(병리사님과)
3. DETR 돌려보기, 보규 코드 리뷰

3/19
to do 
1. deformable convolution/attention deep review
2. image 관련 전처리 라이브러리 확인
3. 준환님 코드 리뷰
4. detr training 시작 가능하면

3/22
to do
1. pip vs conda vs venv 등 설정 경로 확인하기
   jupyter 설정, 어떤 python을 사용하는지 등등..
2. detr kuda error 디버깅
3. pap smier article reading
4. cs231n 강의 수강

done
1. cs231n 3강, 4강 수강
   optimization(svm(hinge) loss, cross entropy)
   back propagation
   
2. detr error debugging 관련
   jupyter에서 torch 등 library 설치한 것이 cuda, cudnn등과 호환이 안된 듯
   conda 가상환경에서 설치할 것, 그 후에 jupyter 연동할 것
3 detr loss ft
t1 = torch.tensor([[0.1928, 0.1385, 0.0804, 0.2328, 0.1787, 0.1768],
        [0.1031, 0.0815, 0.0740, 0.1803, 0.4449, 0.1163],
        [0.1860, 0.1658, 0.0975, 0.2000, 0.1930, 0.1577],
        [0.1302, 0.0783, 0.0818, 0.2376, 0.3783, 0.0938]])
t2 = torch.tensor([2], dtype=torch.int8)   
t1[:,t2]
tensors used as indices must be long, byte or bool tensors
label의 data type을 int8에서 uint8로 변경할 것, unsigned로

3/23
1. cs231n 6강
   data preprocessing
   zero mean, unit variance -> relu is good just for first layer
   batch 단위로 mean, 또는 channel 단위로 (RGB) mean을 구한다. 
   test set에서도 동일..
  activation
  weight initialization
  batch normalization
  training시에 mean과 var를 구하고 test시에 이것을 써서 zero mean unit variance normalization을 해준다.
  
3/24
to do
1. 기존 3 class object detecion training
   code 분석
2. New algorithm 이해


