0221
1. data iteration 부분 확인하고 tf.api.dataset쓰는 것도 한번 고려해 보자.
2. generator 및 zip 관련수정 후 batch iteration 성공, text 분류 성공하였다. 
3. Fasttext 관련 서치
   fasttext training, gensim을 이용 word2vec으로 model load시 out of vocab 에러 발생가능
   직접 fasttext를 로드해야 없는 단어도 벡터화 가능
   문장은 단순히 각 단어 벡터의 평균을 내도 좋다.
   주말동안 word2vec에 대해 학습해 보자.

0224
1. sent2vec을 이용 문장 벡터화 후에 신경망 모델 훈련, 약 75% accuracy
2. sentvec model training시 corpus를 형태소 분석 후 명사, 형용사 부사 동사만 취해서 corpus로 저장후 이것에 대한 fasttext training실시.
   이 sen2vec을 이용 신경망 training시 약 70% 정도 나온다.
3. gensim, sklearn 간단리뷰, sklearn을 통해 count 기반의 bags of word, tf idf표현할 수 있다. 하지만 단어의 개수 등 지정하는 법 아직 모르겠음
   library가 아닌 구현된 코드 이용하는 것도 나쁘지 않다. tf idf는 코드 구해야 됨.
4. bert, text mining의 끝판왕, 복잡하고 시간이 오래 걸릴 듯. pretraining을 많이 해야 한다. 

5. 하고자 하는 모델에 맞게 fine tunning된 모델을 사용해 보자.(bert는 차선)
   1. cnn model에서 input lookup table saving, -> input lookup table은 분류를 하기 위해 가장 적절한 값으로 저장.
      but labeled data가 8000개가 안된다. 
      전체 data를 대상으로 fast text등을 학습시키는 것이 더 좋다.
   2. overlapping window + FCN or convolution ?
      convolution을 하면 중첩해서 쌓았을때 context window가 넓어지는 장점 존재.
      FCN은 window size가 overlapping window로 고정됨, 그 외에는 동일하다.
   3. 영화에서는  9-10 : good, 1~4 : bad로 output class를 2로 두었다. 그렇게 두지 말고 output class도 0~1까지 label에 따라 확률로 둬도 될까?
      그럴 경우에도 cross entropy 계산 가능할까?
      안된다면 평점에 맞게 data를 비례적으로 구성..
      
0225
1. perplexity란 언어모델 관련 측정 도구, training set으로 정확도 측정한다.

0227
1. keras를 이용한 영화리뷰 분류, word embeding, tokenize, dnn,cnn,lstm을 이용한 분류 예제 실행
   https://stackabuse.com/text-classification-with-bert-tokenizer-and-tf-2-0-in-python/
2. bert 예제 실행
   bert embedding 및 bert classify training 모두 gpu outofmemory issue로 training 불가능하다.
   google colab에서 테스트 필요

      
      

   
